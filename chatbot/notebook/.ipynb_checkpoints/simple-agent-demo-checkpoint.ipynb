{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Agent Demo with Model, Tool, and Agent Executor\n",
    "\n",
    "This notebook demonstrates a basic setup with:\n",
    "1. ChatOpenAI model configuration\n",
    "2. Simple tool implementation\n",
    "3. Agent executor setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import tool\n",
    "from langchain.agents import create_openai_functions_agent, AgentExecutor\n",
    "from langchain import hub\n",
    "from langchain_core.messages import HumanMessage\n",
    "import json\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Configuration\n",
    "\n",
    "Using the provided model configuration with qwen3-8B running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model as provided\n",
    "model = ChatOpenAI(\n",
    "    model=\"qwen3-8B\", \n",
    "    base_url=\"http://127.0.0.1:1234/v1\", \n",
    "    api_key=\"\"\n",
    ")\n",
    "\n",
    "print(\"Model initialized successfully!\")\n",
    "print(f\"Model: {model.model_name}\")\n",
    "print(f\"Base URL: {model.openai_api_base}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Tools\n",
    "\n",
    "Creating some simple tools that the agent can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def calculate_sum(a: float, b: float) -> float:\n",
    "    \"\"\"Calculate the sum of two numbers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def calculate_product(a: float, b: float) -> float:\n",
    "    \"\"\"Calculate the product of two numbers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_word_count(text: str) -> int:\n",
    "    \"\"\"Count the number of words in a text.\"\"\"\n",
    "    return len(text.split())\n",
    "\n",
    "# List of tools available to the agent\n",
    "tools = [get_current_time, calculate_sum, calculate_product, get_word_count]\n",
    "\n",
    "print(\"Tools created successfully:\")\n",
    "for tool in tools:\n",
    "    print(f\"- {tool.name}: {tool.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Agent Setup\n",
    "\n",
    "Creating an agent that can use the tools with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to pull the prompt from hub, fallback to a simple prompt if not available\n",
    "try:\n",
    "    prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "    print(\"Successfully loaded prompt from hub\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not load from hub: {e}\")\n",
    "    print(\"Using a simple fallback prompt\")\n",
    "    \n",
    "    from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful assistant that can use tools to answer questions. Use the available tools when needed to provide accurate and helpful responses.\"),\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\", optional=True),\n",
    "        (\"human\", \"{input}\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "    ])\n",
    "\n",
    "print(\"Prompt configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Executor\n",
    "\n",
    "Creating and configuring the agent executor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the agent\n",
    "agent = create_openai_functions_agent(model, tools, prompt)\n",
    "\n",
    "# Create the agent executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, \n",
    "    tools=tools, \n",
    "    verbose=True,\n",
    "    return_intermediate_steps=True\n",
    ")\n",
    "\n",
    "print(\"Agent executor created successfully!\")\n",
    "print(f\"Available tools: {[tool.name for tool in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test the Agent\n",
    "\n",
    "Let's test the agent with some sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Simple greeting (no tools needed)\n",
    "print(\"=== Test 1: Simple Greeting ===\")\n",
    "try:\n",
    "    response = agent_executor.invoke({\"input\": \"Hello! Can you introduce yourself?\"})\n",
    "    print(f\"Response: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Using time tool\n",
    "print(\"=== Test 2: Current Time ===\")\n",
    "try:\n",
    "    response = agent_executor.invoke({\"input\": \"What time is it now?\"})\n",
    "    print(f\"Response: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Using calculation tools\n",
    "print(\"=== Test 3: Mathematical Calculations ===\")\n",
    "try:\n",
    "    response = agent_executor.invoke({\"input\": \"What is 15 + 27? Also, what is 8 * 9?\"})\n",
    "    print(f\"Response: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Using word count tool\n",
    "print(\"=== Test 4: Word Count ===\")\n",
    "try:\n",
    "    response = agent_executor.invoke({\"input\": \"How many words are in this sentence: 'The quick brown fox jumps over the lazy dog'?\"})\n",
    "    print(f\"Response: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 5: Complex query using multiple tools\n",
    "print(\"=== Test 5: Complex Query ===\")\n",
    "try:\n",
    "    response = agent_executor.invoke({\n",
    "        \"input\": \"Can you tell me the current time, calculate 25 + 35, and count the words in 'LangChain is awesome for building AI agents'?\"\n",
    "    })\n",
    "    print(f\"Response: {response['output']}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interactive Testing\n",
    "\n",
    "You can use this cell to test the agent with your own queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive test - modify the query below\n",
    "user_query = \"What tools do you have available?\"\n",
    "\n",
    "try:\n",
    "    response = agent_executor.invoke({\"input\": user_query})\n",
    "    print(f\"Query: {user_query}\")\n",
    "    print(f\"Response: {response['output']}\")\n",
    "    \n",
    "    # Show intermediate steps if any\n",
    "    if response.get('intermediate_steps'):\n",
    "        print(\"\\nIntermediate steps:\")\n",
    "        for step in response['intermediate_steps']:\n",
    "            print(f\"- {step}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "\n",
    "1. **Model Setup**: Configured ChatOpenAI with qwen3-8B running locally\n",
    "2. **Tool Implementation**: Created simple tools for time, calculations, and text processing\n",
    "3. **Agent Executor**: Set up an agent that can intelligently choose and use tools\n",
    "4. **Testing**: Provided examples of how the agent uses different tools\n",
    "\n",
    "The agent can:\n",
    "- Answer questions without tools when appropriate\n",
    "- Use specific tools when needed\n",
    "- Combine multiple tool calls in a single response\n",
    "- Provide detailed and helpful responses\n",
    "\n",
    "**Available Tools:**\n",
    "- `get_current_time`: Get current date and time\n",
    "- `calculate_sum`: Add two numbers\n",
    "- `calculate_product`: Multiply two numbers  \n",
    "- `get_word_count`: Count words in text\n",
    "\n",
    "You can extend this by adding more sophisticated tools like web search, database queries, file operations, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
